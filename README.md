# CMT122-2425-Resources
Resources for CMT122 students (2024-2025).

The course is mandatory for the NLP Master's students and elective for other Master programmes. Therefore, we had a diverse cohort with varying levels in programming and diverse backgrounds.


## Resources for Students Unfamiliar with Python/Coding


- [Blog on recources for beginners](https://josecamachocollados.medium.com/before-getting-started-with-machine-learning-online-tutorials-5bf87fdeb737)

- [Online Python Book](https://runestone.academy/ns/books/published/pythonds/index.html)

- [Python Code Camp Course on YouTube](https://www.youtube.com/@freecodecamp)
  
- [W3S Schools: Introduction to Data Structures and Algorithms](https://www.w3schools.com/dsa/dsa_intro.php#:~:text=Data%20Structures%20is%20about%20how,data%20to%20solve%20problems%20efficiently.)
  
- [Algorithms and Data Structures in Python](https://www.freecodecamp.org/news/learn-algorithms-and-data-structures-in-python/)
  
- [How To Think Like a Computer Scientist: Interactive Edition](https://runestone.academy/ns/books/published/thinkcspy/index.html)
### Resources for Students Unfamiliar with Google Colab
- **Introduction**
   - https://colab.research.google.com/notebooks/welcome.ipynb#
   - [An introduction to Google Colab](https://colab.research.google.com/drive/16pBJQePbqkz3QFV54L4NIkOn1kwpuRrj)
- **Getting started**
  - https://www.marqo.ai/blog/getting-started-with-google-colab-a-beginners-guide
  - https://www.dataquest.io/blog/getting-started-with-google-colab-for-deep-learning/

## Reading and Writing Research Papers
### Reading Papers
- [How to (Seriously) Read a Research Paper?](https://www.science.org/content/article/how-seriously-read-scientific-paper)
### Writing Scientific Papers/Reports
-  **Writing an abstract for your research paper**: https://writing.wisc.edu/handbook/assignments/writing-an-abstract-for-your-research-paper/

- **Presenting your research: Writing NLP papers** by Christopher Potts: https://web.stanford.edu/class/cs224u/2021/slides/cs224u-2021-presenting-part2-handout.pdf

- **How to write an okay research paper** by Sasha Rush (video): https://www.youtube.com/watch?v=qNlwVGxkG7Q

- **Tips for Writing NLP Papers** by Vered Schwartz: https://medium.com/@vered1986/tips-for-writing-nlp-papers-9c729a2f9e1f

- **Ethics Reviewer Tutorial** by ARR: https://aclrollingreview.org/ethicsreviewertutorial

- **Writing a System description Paper for SemEval 2025 Task 11** by Nedjma Ousidhoum: https://github.com/nedjmaou/Writing_a_task_description_paper

## Additional Resources for for Class Content
### Introduction to ML for NLP (General Resources)
-	Speech and Language Processing (3rd ed. draft) by Dan Jurafsky and James H. Martin: https://web.stanford.edu/~jurafsky/slp3/
- Text Processing with NLTK: https://realpython.com/nltk-nlp-python/
- Getting Started with NLP by Ekaterina Kochmar: https://github.com/ekochmar/Getting-Started-with-NLP
- HuggingFace NLP course: https://huggingface.co/learn/nlp-course/chapter1/1
- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition by Aurélien Géron: https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/
- Blogpost on Machine learning classifiers: https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623
- Introduction to Machine Learning for Coders (Fast.ai): http://course18.fast.ai/ml 
- Machine Learning with Python (Coursera): http://tiny.cc/cz5bjz 
- Advanced Machine Learning Specialization (Coursera): http://tiny.cc/3u5bjz 
- Machine Learning (VU Amsterdam): https://mlvu.github.io/ 
- Another list with more resources (Ai2 Blog): https://medium.com/ai2-blog/how-to-get-up-to-speed-on-machine-learning-and-ai-a0fd923d4169 
#### Some NLP Classes
- CMSC 726 by Jordan Boyd-Graber: http://users.umiacs.umd.edu/~jbg/teaching/CMSC_726/ and http://users.umiacs.umd.edu/~jbg/teaching/CMSC_723/
- STAT 479: Machine Learning (FS 2019) taught by Sebastian Raschka at the University of Wisconsin-Madison: https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/README.md  
- NLP class by Jaob Eisenstein https://github.com/jacobeisenstein/gt-nlp-class/tree/master/2017-materials
- NLP class by Christopher Manning https://web.stanford.edu/class/cs224n/
- NLP course by Lena Voita https://lena-voita.github.io/nlp_course.html
#### Some videos 
- Christopher Manning: https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ
- Jordan Boyd-Graber: https://www.youtube.com/watch?v=7DjSOLW-ozc&list=PLegWUnz91WfsELyRcZ7d1GwAVifDaZmgo

### Neural Nets and Deep Learning 
- Neural Networks by Jurafsly and Martin: https://web.stanford.edu/~jurafsky/slp3/7.pdf
- RNNs and LSTMs by Jurafsky and Martin https://web.stanford.edu/~jurafsky/slp3/8.pdf
- Backpropagation explainer demo by Donald Bertucci and Minsuk Kahng: https://xnought.github.io/backprop-explainer/
- Dive into Deep Learning: https://d2l.ai/ 
- But what is a neural network? (video-introduction): https://www.youtube.com/watch?v=aircAruvnKk 
- Assembly AI https://github.com/AssemblyAI/youtube-tutorials  and video): https://www.youtube.com/watch?v=dccdadl90vs&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX
- Introduction to Neural Networks by Ujjwal Karn: https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/ 
- Introduction to Neural Nets by Victor Zhou: https://victorzhou.com/blog/intro-to-neural-networks/
- Convolutional Neural Nets by Lena Voita: https://lena-voita.github.io/nlp_course/models/convolutional.html

### Language Models
- Language Modeling by Lena Voita https://lena-voita.github.io/nlp_course/language_modeling.html
- Mirella Lapata’s talk about Generative AI: https://www.youtube.com/watch?v=_6R7Ym6Vy_I&t=2303s
- Transformers by Jurafsky and Martin https://web.stanford.edu/~jurafsky/slp3/9.pdf
- Illustrated BERT by Jay Alammar: https://jalammar.github.io/illustrated-bert/
- https://medium.com/@kirudang/language-model-history-before-and-after-transformer-the-ai-revolution-bedc7948a130
- N-gram Language models by Jurafsky and Martin: https://web.stanford.edu/~jurafsky/slp3/3.pdf
- Neural Language Models by Jurafsky and Martin: https://web.stanford.edu/~jurafsky/slp3/8.pdf
- Large Language Models by Jurafsky and Martin: https://web.stanford.edu/~jurafsky/slp3/10.pdf
- Masked Language Models by Jurafsky and Martin: https://web.stanford.edu/~jurafsky/slp3/11.pdf
- Build a Large Language Model (From Scratch) by Sebastian Raschka (Chapter 1): https://livebook.manning.com/book/build-a-large-language-model-from-scratch/chapter-1/v-8/
- Thinking Like Transformer by Sasha Rush and Gail Weiss: https://srush.github.io/raspy/
- The Full Story of Large Language Models and RLHF by Marco Ramponi: ttps://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/
- A Comprehensive Overview of Transformer-Based Models by Minhajul Hoque: Encoders, Decoders, and More by https://medium.com/@minh.hoque/a-comprehensive-overview-of-transformer-based-models-encoders-decoders-and-more-e9bc0644a4e5
- A Very Gentle Introduction to Large Language Models without the Hype by Mark Riedl: https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e





